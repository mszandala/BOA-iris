# -*- coding: utf-8 -*-
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
import time
import math
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D


# Wczytanie danych
iris = load_iris()
X, y = iris.data, iris.target


def evaluate_k(k_value, X_local, y_local, cv=5):
    """Oblicza bd klasyfikacji (1 - dokadno) dla podanej wartoci K
    za pomoc walidacji krzy偶owej.
    Zwraca korygowan warto K (nieparzyst) oraz bd (1 - accuracy).
    """
    # Jeli wejcie nie jest liczb (NaN, inf), zwracamy wysoki bd
    if not np.isfinite(k_value):
        return 1.0, max(1, int(K_min))

    # Oblicz przybli偶ony rozmiar zbioru treningowego dla danego cv
    n_samples = len(y_local)
    # Dla cv=int zakadamy r贸wny podzia; rozmiar treningu to n_samples - (n_samples // cv)
    try:
        n_train = n_samples - (n_samples // int(cv))
    except Exception:
        n_train = max(1, n_samples - 1)

    # Konwersja i nao偶enie granic
    k = max(1, int(round(k_value)))
    if k % 2 == 0:
        k += 1

    # Jeli k jest wiksze ni偶 pr贸b treningowych, ograniczamy do mo偶liwego maksimum
    if k > n_train:
        # Nie mo偶emy u偶y n_neighbors wikszego ni偶 liczba pr贸bek w zbiorze uczcym
        # Zwracamy wysoki bd (unikamy wyjtku w cross_val_score)
        return 1.0, n_train if n_train >= 1 else 1

    knn = KNeighborsClassifier(n_neighbors=k)
    try:
        scores = cross_val_score(knn, X_local, y_local, cv=cv, scoring='accuracy')
        mean_accuracy = np.mean(scores)
        error_rate = 1 - mean_accuracy
        # Jeli otrzymalimy NaN w score, potraktuj jako zy wynik
        if not np.isfinite(error_rate):
            return 1.0, k
        return error_rate, k
    except Exception:
        # Jeli co p贸jdzie nie tak (np. ValueError z powodu nieprawidowego k),
        # zwracamy maksymalny bd.
        return 1.0, k


# 1. Parametry BOA dla K-NN
N = 5          # Wielko populacji (ilo mottyli)
MaxIter = 60    # Liczba iteracji BOA
p = 0.2         # Prawdopodobiestwo przeczania (To okrela, czy motyl leci w stron najlepszego motyla (eksploatacja), czy losowo w stron innych (eksploracja))
alpha = 0.1     # Wykadnik mocy (sia zapachu)
c_init = 0.15   # Wsp贸czynnik sensoryczny
K_min = 1       # Minimalna warto K (Dolna Granica)
K_max = 120      # Maksymalna warto K (G贸rna Granica)

def run_boa_for_k(X_local, y_local, N, MaxIter, p, alpha, c_init, K_min, K_max):
    """Prosta implementacja BOA dla doboru parametru K dla KNN.
    Zwraca (best_K, best_error, history)
    """
    # Ustawiamy granic g贸rn K tak, aby nie przekracza rozmiaru zbioru treningowego
    n_samples = len(y_local)
    n_train = n_samples - (n_samples // 5)
    safe_K_max = min(K_max, max(1, n_train))

    positions = np.random.uniform(K_min, safe_K_max, N)
    fitness = np.array([evaluate_k(pos, X_local, y_local, cv=5)[0] for pos in positions])
    # Zastp NaN (np.inf) du偶ym bdem, by nie psu wyboru najlepszego
    fitness = np.array([f if np.isfinite(f) else 1.0 for f in fitness])

    best_index = np.argmin(fitness)
    g_star = positions[best_index]
    best_fitness = fitness[best_index]
    best_K = evaluate_k(g_star, X_local, y_local, cv=5)[1]

    c = c_init
    history = []
    positions_history = []
    fitness_history = []


    print(f"\n=== START BOA ===")
    print(f"Pocztkowy najlepszy K: {best_K:.2f}, bd: {best_fitness:.4f}\n")

    for t in range(MaxIter):
        c = c_init * (1 - t / MaxIter)  # c maleje z ka偶d iteracj
        for i in range(N):
            I_i = fitness[i]
            f_i = c * (I_i ** alpha)
            r = np.random.rand()
            x_i_t = positions[i]

            if r < p:
                x_i_next = x_i_t + (r ** 2 * g_star - x_i_t) * f_i
            else:
                candidates = list(range(N))
                candidates.pop(i)
                j, k = np.random.choice(candidates, 2, replace=False)
                x_j_t = positions[j]
                x_k_t = positions[k]
                x_i_next = x_i_t + (r ** 2 * x_j_t - x_k_t) * f_i

            x_i_next = np.clip(x_i_next, K_min, K_max)
            new_error_rate, new_k_value = evaluate_k(x_i_next, X_local, y_local, cv=5)
            if not np.isfinite(new_error_rate):
                new_error_rate = 1.0

            if new_error_rate < fitness[i]:
                positions[i] = x_i_next
                fitness[i] = new_error_rate
                if new_error_rate < best_fitness:
                    best_fitness = new_error_rate
                    g_star = x_i_next
                    best_K = new_k_value

        #  Komunikaty kontrolne co iteracj:
        mean_fitness = np.mean(fitness)
        print(f"Iteracja {t+1}/{MaxIter}: najlepszy_K={best_K:.0f}, "
              f"najlepszy_bd={best_fitness:.4f}, redni_bd={mean_fitness:.4f}")

        positions_history.append(positions.copy())
        fitness_history.append(fitness.copy())

        history.append((t, best_K, best_fitness))      

    print("\n=== KONIEC BOA ===")
    print(f"Najlepszy znaleziony K: {best_K:.0f}, kocowy bd: {best_fitness:.4f}\n")

    return best_K, best_fitness, history, positions_history, fitness_history


if __name__ == '__main__':
    # 1) Baseline: klasyczny KNN (domylnie n_neighbors)
    baseline_k = 30
    knn_baseline = KNeighborsClassifier(n_neighbors=baseline_k)
    start = time.time()
    baseline_scores = cross_val_score(knn_baseline, X, y, cv=5, scoring='accuracy')
    baseline_mean = float(np.mean(baseline_scores))
    baseline_time = time.time() - start

    # 2) BOA: szukamy najlepszego K
    t0 = time.time()
    best_K, best_error, history, positions_history, fitness_history = run_boa_for_k(
    X, y, N=N, MaxIter=MaxIter, p=p, alpha=alpha, c_init=c_init, K_min=K_min, K_max=K_max
)
    boa_time = time.time() - t0
    best_accuracy = 1 - best_error

    # 3) Por贸wnanie i zapis wynik贸w
    summary_lines = []
    summary_lines.append("=== Por贸wnanie: klasyczny KNN vs BOA-optymalizowany KNN ===")
    summary_lines.append(f"Dataset: Iris ({X.shape[0]} pr贸bek, {X.shape[1]} cech)")
    summary_lines.append("")
    summary_lines.append("-- Klasyczny KNN (baseline)")
    summary_lines.append(f"K (domylne): {baseline_k}")
    summary_lines.append(f"rednia dokadno (5-fold CV): {baseline_mean * 100:.2f}%")
    summary_lines.append(f"Czas wykonania: {baseline_time:.2f} s")
    summary_lines.append("")
    summary_lines.append("-- BOA + KNN")
    summary_lines.append(f"Najlepsze K znalezione przez BOA: {best_K}")
    summary_lines.append(f"rednia dokadno KNN (5-fold CV) z najlepszym K: {best_accuracy * 100:.2f}%")
    summary_lines.append(f"Czas optymalizacji BOA: {boa_time:.2f} s")
    summary_lines.append("")
    diff = (best_accuracy - baseline_mean) * 100
    summary_lines.append(f"R贸偶nica (BOA - baseline): {diff:+.2f} punkt贸w procentowych")

    print("\n".join(summary_lines))
    
    # ============================================
    #  WYKRESY KONWERGENCJI BOA
    # ============================================

    # Dane do 2D
    iterations = [h[0] for h in history]
    best_K_values = [h[1] for h in history]
    best_errors = [h[2] for h in history]

    # --- (1) K vs Iteracja ---
    plt.figure(figsize=(8, 5))
    plt.plot(iterations, best_K_values, marker='o', color='royalblue')
    plt.title("Zmiana najlepszego K w czasie (BOA)")
    plt.xlabel("Iteracja")
    plt.ylabel("Najlepsze K")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # --- (2) Bd vs Iteracja ---
    plt.figure(figsize=(8, 5))
    plt.plot(iterations, best_errors, marker='o', color='tomato')
    plt.title("Zmiana najlepszego bdu w czasie (BOA)")
    plt.xlabel("Iteracja")
    plt.ylabel("Bd (1 - accuracy)")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # --- (3) 3D: Iteracja - K - Bd ---
    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111, projection='3d')

    for i in range(N):
        ax.plot(
            range(MaxIter),
            [positions_history[t][i] for t in range(MaxIter)],
            [fitness_history[t][i] for t in range(MaxIter)],
            alpha=0.6
        )

    ax.set_xlabel("Iteracja")
    ax.set_ylabel("Warto K")
    ax.set_zlabel("Bd (1 - accuracy)")
    ax.set_title("Ewolucja pozycji motyli (BOA 3D)")
    plt.show()


    try:
        with open("result.txt", "w", encoding="utf-8") as f:
            for ln in summary_lines:
                f.write(ln + "\n")
        print("Wyniki zapisano do result.txt")
    except Exception as e:
        print(f"Nie udao si zapisa wynik贸w do pliku: {e}")